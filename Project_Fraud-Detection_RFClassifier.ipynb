{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the machine learning model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import GridSearchCV for finding the model with the best parameters\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import functions for measuring metrics of the ml model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Import the Train, Validation, and Test data sets\n",
    "trainF = pd.read_csv('./train_features.csv')\n",
    "trainL = pd.read_csv('./train_labels.csv')\n",
    "\n",
    "valF = pd.read_csv('./validation_features.csv')\n",
    "valL = pd.read_csv('./validation_labels.csv')\n",
    "\n",
    "testF = pd.read_csv('./test_features.csv')\n",
    "testL = pd.read_csv('./test_labels.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Random Forest Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuring the Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Create 3 RandomForestClassifiers with the best hyperparameters\n",
    "rfModel1 = RandomForestClassifier(n_estimators=50, max_depth=10)\n",
    "rfModel1.fit(trainF, trainL.values.ravel())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=50)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# def printResults(gridSearchResults):\n",
    "\n",
    "#     print( 'Best ML HyperParameters: {}\\n'.format(gridSearchResults.best_params_) )\n",
    "\n",
    "#     means = gridSearchResults.cv_results_['mean_test_score']\n",
    "#     stnDvs = gridSearchResults.cv_results_['std_test_score']\n",
    "\n",
    "#     for mean, stnDvs, parameters in zip( means, stnDvs, gridSearchResults.cv_results_['params'] ):\n",
    "#         print(\n",
    "#             '{} (+/-{}) for {}'.format(\n",
    "#                 round(mean, 3),\n",
    "#                 round(stnDvs*2, 3),\n",
    "#                 parameters\n",
    "#             )\n",
    "#         )    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# # Instantiate the Random Forest Classifier and set the hyperparameters\n",
    "# rfModel = RandomForestClassifier()\n",
    "\n",
    "# hyperparameters = {\n",
    "#     'n_estimators': [5, 50, 100],\n",
    "#     'max_depth': [2, 10, 20, None]\n",
    "# }\n",
    "\n",
    "# # GridSearchCV will search and rank the models as per the parameters\n",
    "# gridSearch = GridSearchCV( rfModel, hyperparameters, cv=5 )\n",
    "\n",
    "# # .fit() for the model to learn the parameters\n",
    "# gridSearch.fit( trainF, trainL.values.ravel() )\n",
    "\n",
    "# printResults( gridSearch )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 1.0 (+/-0.0) for {'max_depth': None, 'n_estimators': 5}\n",
    "# 1.0 (+/-0.0) for {'max_depth': None, 'n_estimators': 50}\n",
    "# 1.0 (+/-0.0) for {'max_depth': None, 'n_estimators': 100}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Adjust the paramaters after validation test dataset\n",
    "predLabel = rfModel1.predict(valF)\n",
    "predLabel"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Use the test data set with the best available model\n",
    "predLabel = rfModel1.predict(testF)\n",
    "\n",
    "accuracy = round(accuracy_score(testL, predLabel), 3)\n",
    "precision = round(precision_score(testL, predLabel), 3)\n",
    "recall = round(recall_score(testL, predLabel), 3)\n",
    "\n",
    "print(\n",
    "        'Max depth: {} and Estimators: {} ---> Accuracy: {}, Precision: {}, Recall: {}'\n",
    "        .format(rfModel1.max_depth, rfModel1.n_estimators, accuracy, precision, recall)\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max depth: 10 and Estimators: 50 ---> Accuracy: 1.0, Precision: 1.0, Recall: 1.0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}